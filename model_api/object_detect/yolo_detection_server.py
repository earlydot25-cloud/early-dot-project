import base64
import json
import numpy as np
import cv2
import torch
import time
from io import BytesIO
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from ultralytics import YOLO

# -------------------------------------------------------------
# 1. ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì ì œê³µ ê²½ë¡œ)
# -------------------------------------------------------------
MODEL_WEIGHTS_PATH = "models/yolo/yolo_batch8_epoch50_best.pt"

# -------------------------------------------------------------
# 2. FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ë° ëª¨ë¸ ë¡œë“œ
# -------------------------------------------------------------
app = FastAPI(title="YOLO Real-time Detection API")
yolo_model: YOLO | None = None
DEVICE = 'cpu'  # ê¸°ë³¸ ì¥ì¹˜ ì„¤ì •

# ğŸ’¡ [ì¶”ê°€] ì¥ì¹˜ ìë™ ê²°ì • ë¡œì§
if torch.cuda.is_available():
    DEVICE = 'cuda'  # NVIDIA GPU (CUDA) ì‚¬ìš© ê°€ëŠ¥
elif torch.backends.mps.is_available():
    DEVICE = 'mps'  # Apple Silicon (MPS) ì‚¬ìš© ê°€ëŠ¥

print(f"âœ¨ ëª¨ë¸ ì¶”ë¡  ì¥ì¹˜ ì„¤ì •: {DEVICE}")


# ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ì„ ë¯¸ë¦¬ ë¡œë“œ
@app.on_event("startup")
async def load_model():
    global yolo_model
    print(f"âœ¨ ëª¨ë¸ ë¡œë“œ ì¤‘: {MODEL_WEIGHTS_PATH}")
    try:
        # ëª¨ë¸ ë¡œë“œ ë° ê²°ì •ëœ ì¥ì¹˜ë¡œ ì´ë™
        yolo_model = YOLO(MODEL_WEIGHTS_PATH)
        yolo_model.to(DEVICE)  # ğŸ’¡ [ìˆ˜ì •] ëª¨ë¸ì„ GPU/MPS ì¥ì¹˜ë¡œ ì´ë™
        print(f"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. (ì¥ì¹˜: {DEVICE})")
    except Exception as e:
        print(f"ğŸš¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        # ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ì„œë²„ ì‹œì‘ì„ ì¤‘ë‹¨í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


# -------------------------------------------------------------
# 3. ìš”ì²­ ë° ì‘ë‹µ ë°ì´í„° ëª¨ë¸ (ë¶„ë¥˜/ì‹ ë¢°ë„ ì œê±°)
# -------------------------------------------------------------

# í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë³´ë‚¼ ìš”ì²­ ë°ì´í„° êµ¬ì¡°
class ImageRequest(BaseModel):
    # 'data:image/jpeg;base64,...' í˜•ì‹ì˜ Base64 ë¬¸ìì—´
    image_base64: str


# ğŸ’¡ [ìˆ˜ì •] íƒì§€ ê²°ê³¼ êµ¬ì¡°: ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë§Œ í¬í•¨
class DetectionResult(BaseModel):
    # [x1, y1, x2, y2] - 0ë¶€í„° 1000 ì‚¬ì´ì˜ ì •ê·œí™”ëœ ì¢Œí‘œ
    box: list[int]


# -------------------------------------------------------------
# 4. ì´ë¯¸ì§€ ë””ì½”ë”© ë° ì „ì²˜ë¦¬ í•¨ìˆ˜
# -------------------------------------------------------------
def decode_base64_image(base64_string: str) -> np.ndarray:
    """Base64 ë¬¸ìì—´ì„ OpenCV ì´ë¯¸ì§€ ë°°ì—´(numpy ndarray)ë¡œ ë””ì½”ë”©í•©ë‹ˆë‹¤."""
    try:
        # 'data:image/jpeg;base64,' ë¶€ë¶„ì„ ì œê±°í•˜ê³  ì‹¤ì œ Base64 ë°ì´í„°ë§Œ ì¶”ì¶œ
        header, encoded = base64_string.split(',', 1)

        # Base64 ë””ì½”ë”©
        decoded_data = base64.b64decode(encoded)

        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        np_arr = np.frombuffer(decoded_data, np.uint8)

        # OpenCVë¡œ ë””ì½”ë”© (BGR í˜•ì‹)
        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

        if img is None:
            raise ValueError("CV2 ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")

        print(f"ğŸ“¸ [BACKEND] ë””ì½”ë”© ì„±ê³µ. ì´ë¯¸ì§€ í¬ê¸°: {img.shape}")

        return img

    except Exception as e:
        print(f"ğŸš¨ [BACKEND] ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {e}")


# -------------------------------------------------------------
# 5. íƒì§€ API ì—”ë“œí¬ì¸íŠ¸
# -------------------------------------------------------------
@app.post("/api/detect/stream", response_model=list[DetectionResult])
async def stream_detection(request: ImageRequest):
    """ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡ëœ Base64 ì´ë¯¸ì§€ì— ëŒ€í•´ YOLO ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""

    if yolo_model is None:
        print("ğŸš¨ [BACKEND] ì—ëŸ¬: ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 503 ë°˜í™˜.")
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    start_time = time.time()

    # 1. Base64 ë””ì½”ë”© ë° ì´ë¯¸ì§€ ë¡œë“œ
    img_bgr = decode_base64_image(request.image_base64)
    H, W, _ = img_bgr.shape  # ì´ë¯¸ì§€ì˜ ë†’ì´ì™€ ë„ˆë¹„

    # 2. YOLO ì¶”ë¡  ì‹¤í–‰
    # ğŸ’¡ [ìˆ˜ì •] conf=0.7ë¡œ ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ì„¤ì •í•˜ì—¬ ë„ˆë¬´ ë§ì€ íƒì§€ ê²°ê³¼ ë°©ì§€
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ 300ms ê°„ê²©ìœ¼ë¡œ í˜¸ì¶œë˜ë¯€ë¡œ, ì¶”ë¡  ì‹œê°„(inference time) ìì²´ëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    # ë§Œì•½ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë„ˆë¬´ ëŠë¦¬ë‹¤ë©´, delay_msë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    results = yolo_model.predict(
        source=img_bgr,
        device=DEVICE,
        conf=0.7,  # ğŸ’¡ [ì¶”ê°€] ì‹ ë¢°ë„ 0.7 ë¯¸ë§Œì¸ ê²°ê³¼ëŠ” ë¬´ì‹œ
        verbose=False
    )

    end_time = time.time()

    detections: list[DetectionResult] = []

    # 3. ë°”ìš´ë”© ë°•ìŠ¤ ê²°ê³¼ ì²˜ë¦¬ ë° ì •ê·œí™”
    if results and len(results) > 0:
        result = results[0]

        # ğŸ’¡ [ìˆ˜ì •] ì‹ ë¢°ë„ì™€ ë¼ë²¨ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì˜¤ì§ ë°”ìš´ë”© ë°•ìŠ¤ë§Œ ì¶”ì¶œ
        for box in result.boxes:
            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ [x1, y1, x2, y2] (í”½ì…€ ë‹¨ìœ„)
            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())

            # ì¢Œí‘œ ì •ê·œí™” (0~1000 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜)
            n_x1 = int((x1 / W) * 1000)
            n_y1 = int((y1 / H) * 1000)
            n_x2 = int((x2 / W) * 1000)
            n_y2 = int((y2 / H) * 1000)

            # ğŸ’¡ [ìˆ˜ì •] DetectionResultì— boxë§Œ ì¶”ê°€
            detections.append(DetectionResult(
                box=[n_x1, n_y1, n_x2, n_y2]
            ))

    print(f"ğŸ” [BACKEND] íƒì§€ ì™„ë£Œ. ê°ì²´ ìˆ˜: {len(detections)}, ì¶”ë¡  ì‹œê°„: {end_time - start_time:.4f}s")

    return detections